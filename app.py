import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.compose import ColumnTransformer
from scipy.cluster.hierarchy import dendrogram, linkage, fcluster
from sklearn.decomposition import PCA
from sklearn.tree import DecisionTreeClassifier, plot_tree
from sklearn.model_selection import train_test_split
import warnings
warnings.filterwarnings('ignore')
import io

# –î–æ–±–∞–≤–ª—è–µ–º –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–ª—è —Ç—è–∂–µ–ª—ã—Ö —Ñ—É–Ω–∫—Ü–∏–π
@st.cache_data
def comprehensive_clean_data_cached(df, remove_outliers=True, outlier_multiplier=1.5, numeric_columns=None):
    """–ö—ç—à–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è —Ñ—É–Ω–∫—Ü–∏–∏ –æ—á–∏—Å—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö"""
    return comprehensive_clean_data(df, remove_outliers, outlier_multiplier, numeric_columns)

@st.cache_data
def encoded_features_cached(df, num_columns, cat_columns):
    """–ö—ç—à–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è —Ñ—É–Ω–∫—Ü–∏–∏ –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è"""
    return encoded_features(df, num_columns, cat_columns)

def show_info(df):
    """
    –§—É–Ω–∫—Ü–∏—è –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è –æ—Å–Ω–æ–≤–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –¥–∞—Ç–∞—Ñ—Ä–µ–π–º–µ –≤ Streamlit
    """
    if df is not None and not df.empty:
        st.markdown("---")
        st.subheader("üìä –û—Å–Ω–æ–≤–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –¥–∞—Ç–∞—Ñ—Ä–µ–π–º–µ")
        
        # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Å—Ç—Ä—É–∫—Ç—É—Ä–µ
        st.write("**1. –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Å—Ç—Ä—É–∫—Ç—É—Ä–µ:**")
        buffer = io.StringIO()
        df.info(buf=buffer)
        info_str = buffer.getvalue()
        st.text(info_str)
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ
        st.write("**2. –°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ —á–∏—Å–ª–æ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤:**")
        st.dataframe(df.describe())
        
        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
        st.write("**3. –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è:**")
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric("–†–∞–∑–º–µ—Ä –¥–∞—Ç–∞—Ñ—Ä–µ–π–º–∞", f"{df.shape[0]} √ó {df.shape[1]}")
        
        with col2:
            st.metric("–í—Å–µ–≥–æ –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π", df.isnull().sum().sum())
        
        with col3:
            st.metric("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤", df.duplicated().sum())
        
        with col4:
            numeric_cols = df.select_dtypes(include=[np.number]).shape[1]
            st.metric("–ß–∏—Å–ª–æ–≤—ã–µ —Å—Ç–æ–ª–±—Ü—ã", numeric_cols)
        
        # –î–µ—Ç–∞–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏—è—Ö
        st.write("**4. –î–µ—Ç–∞–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏—è—Ö:**")
        missing_data = df.isnull().sum()
        missing_percent = (missing_data / len(df)) * 100
        missing_df = pd.DataFrame({
            '–ö–æ–ª–æ–Ω–∫–∞': missing_data.index,
            '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–æ–ø—É—Å–∫–æ–≤': missing_data.values,
            '–ü—Ä–æ—Ü–µ–Ω—Ç –ø—Ä–æ–ø—É—Å–∫–æ–≤': missing_percent.values
        })
        missing_df = missing_df[missing_df['–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–æ–ø—É—Å–∫–æ–≤'] > 0]
        
        if not missing_df.empty:
            st.dataframe(missing_df)
        else:
            st.success("‚úÖ –ü—Ä–æ–ø—É—â–µ–Ω–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π –Ω–µ—Ç")
            
    else:
        st.warning("–î–∞—Ç–∞—Å–µ—Ç –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω –∏–ª–∏ –ø—É—Å—Ç–æ–π")

def encoded_features(df, num_columns, cat_columns):
    """–ö–æ–¥–∏—Ä—É–µ—Ç —á–∏—Å–ª–æ–≤—ã–µ –∏ –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –¥–∞—Ç–∞—Ñ—Ä–µ–π–º–∞"""
    df_encoded = df.copy()
    
    # –ü—Ä–∏–º–µ–Ω—è–µ–º LabelEncoder –∫ –∫–∞–∂–¥–æ–π –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω–æ–π –∫–æ–ª–æ–Ω–∫–µ
    label_encoders = {}
    for col in cat_columns:
        le = LabelEncoder()
        df_encoded[col] = le.fit_transform(df_encoded[col].astype(str))
        label_encoders[col] = le

    # –¢–µ–ø–µ—Ä—å –≤—Å–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ —á–∏—Å–ª–æ–≤—ã–µ
    all_features = num_columns + cat_columns

    # –ú–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º –≤—Å–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
    preprocessor = ColumnTransformer(
        transformers=[
            ('scaler', StandardScaler(), all_features)
        ])

    X_processed = preprocessor.fit_transform(df_encoded)

    return X_processed, label_encoders, preprocessor

def plot_dendogram_features(X_processed, feature_names):
    """–ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –¥–µ–Ω–¥–æ–≥—Ä–∞–º–º—ã –ø—Ä–∏–∑–Ω–∞–∫–æ–≤"""
    Z_features = linkage(X_processed.T, method='ward', metric='euclidean')

    fig, ax = plt.subplots(figsize=(16, 10))
    dendrogram(Z_features,
               labels=feature_names,
               leaf_rotation=90,
               leaf_font_size=10,
               show_contracted=True,
               color_threshold=0.7 * max(Z_features[:, 2]),
               ax=ax)

    ax.set_title('–î–µ–Ω–¥—Ä–æ–≥—Ä–∞–º–º–∞ –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏ –ü–†–ò–ó–ù–ê–ö–û–í\n(–≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ –ø–æ—Ö–æ–∂–∏—Ö —Ñ–∏—á–µ–π)', 
                 fontsize=14, fontweight='bold', pad=20)
    ax.set_xlabel('–†–µ–∞–ª—å–Ω—ã–µ –Ω–∞–∑–≤–∞–Ω–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤', fontsize=12)
    ax.set_ylabel('–†–∞—Å—Å—Ç–æ—è–Ω–∏–µ', fontsize=12)
    ax.grid(axis='y', alpha=0.3)
    plt.tight_layout()
    
    return fig

def calculate_inertia(Z, n_clusters, X_processed):
    """–°—Ç—Ä–æ–∏—Ç –∏–Ω–µ—Ä—Ü–∏—é –¥–ª—è –º–µ—Ç–æ–¥–∞ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –∫–æ–ª-–≤–∞ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤ —Å –ø–æ–º–æ—â—å—é –ª–æ–∫—Ç—è"""
    clusters = fcluster(Z, n_clusters, criterion='maxclust')
    inertia = 0
    for i in range(1, n_clusters + 1):
        cluster_points = X_processed[clusters == i]
        if len(cluster_points) > 0:
            centroid = cluster_points.mean(axis=0)
            inertia += np.sum((cluster_points - centroid) ** 2)
    return inertia

def find_elbow_point(inertias, cluster_range):
    """–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –Ω–∞—Ö–æ–¥–∏—Ç —Ç–æ—á–∫—É –ª–æ–∫—Ç—è –Ω–∞ –≥—Ä–∞—Ñ–∏–∫–µ –∏–Ω–µ—Ä—Ü–∏–∏"""
    first_diff = np.diff(inertias)
    second_diff = np.diff(first_diff)
    
    # –ù–∞—Ö–æ–¥–∏–º —Ç–æ—á–∫—É –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–≥–æ –∏–∑–≥–∏–±–∞
    elbow_idx = np.argmax(np.abs(second_diff)) + 1  
    
    return list(cluster_range)[elbow_idx]

def comprehensive_clean_data(df, remove_outliers=True, 
                           outlier_multiplier=1.5, numeric_columns=None):
    """–ö–æ–º–ø–ª–µ–∫—Å–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö - –≤—Å–µ–≥–¥–∞ —É–¥–∞–ª—è–µ–º –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è"""
    df_clean = df.copy()
    
    # –í—Å–µ–≥–¥–∞ —É–¥–∞–ª—è–µ–º –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
    initial_shape = df_clean.shape
    df_clean = df_clean.dropna()
    st.write(f"–£–¥–∞–ª–µ–Ω–æ —Å—Ç—Ä–æ–∫ —Å –ø—Ä–æ–ø—É—Å–∫–∞–º–∏: {initial_shape[0] - df_clean.shape[0]}")
    
    # –£–¥–∞–ª–µ–Ω–∏–µ –≤—ã–±—Ä–æ—Å–æ–≤ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
    if remove_outliers and numeric_columns:
        initial_shape = df_clean.shape
        for col in numeric_columns:
            if col in df_clean.columns:
                Q1 = df_clean[col].quantile(0.25)
                Q3 = df_clean[col].quantile(0.75)
                IQR = Q3 - Q1
                lower_bound = Q1 - outlier_multiplier * IQR
                upper_bound = Q3 + outlier_multiplier * IQR
                df_clean = df_clean[(df_clean[col] >= lower_bound) & (df_clean[col] <= upper_bound)]
        st.write(f"–£–¥–∞–ª–µ–Ω–æ —Å—Ç—Ä–æ–∫ —Å –≤—ã–±—Ä–æ—Å–∞–º–∏: {initial_shape[0] - df_clean.shape[0]}")
    
    return df_clean

def delete_cat_with_zero_dispersion(df, cat_cols, threshold=0.95):
    """–£–¥–∞–ª—è–µ—Ç –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ —Å—Ç–æ–ª–±—Ü—ã —Å –º–∞–ª–µ–Ω—å–∫–æ–π –¥–∏—Å–ø–µ—Ä—Å–∏–µ–π –∑–Ω–∞—á–µ–Ω–∏–π"""
    cols_to_drop = []
    
    for col in cat_cols:
        if col in df.columns:
            value_counts = df[col].value_counts(normalize=True)
            most_common_ratio = value_counts.iloc[0] if len(value_counts) > 0 else 1.0
            
            if most_common_ratio >= threshold:
                cols_to_drop.append(col)
                st.write(f"–ö–æ–ª–æ–Ω–∫–∞ '{col}' —É–¥–∞–ª–µ–Ω–∞: –¥–æ–ª—è —Å–∞–º–æ–≥–æ —á–∞—Å—Ç–æ–≥–æ –∑–Ω–∞—á–µ–Ω–∏—è = {most_common_ratio:.3f}")
    
    if cols_to_drop:
        df = df.drop(columns=cols_to_drop)
        st.write(f"–£–¥–∞–ª–µ–Ω–æ –∫–æ–ª–æ–Ω–æ–∫: {len(cols_to_drop)}")
    else:
        st.write("–ù–µ—Ç –∫–æ–ª–æ–Ω–æ–∫ —Å –Ω–∏–∑–∫–æ–π –¥–∏—Å–ø–µ—Ä—Å–∏–µ–π –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è")
    
    return df

def plot_numeric_distributions(df, columns, cols=3):
    """–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —á–∏—Å–ª–æ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤"""
    n = len(columns)
    rows = (n + cols - 1) // cols
    
    fig, axes = plt.subplots(rows, cols, figsize=(5*cols, 4*rows))
    if rows == 1:
        axes = [axes] if cols == 1 else axes
    else:
        axes = axes.flatten()
    
    for i, col in enumerate(columns):
        if i < len(axes):
            df[col].hist(ax=axes[i], bins=30, alpha=0.7)
            axes[i].set_title(f'–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ {col}')
            axes[i].set_xlabel(col)
            axes[i].set_ylabel('–ß–∞—Å—Ç–æ—Ç–∞')
    
    # –°–∫—Ä—ã–≤–∞–µ–º –ø—É—Å—Ç—ã–µ subplots
    for i in range(n, len(axes)):
        axes[i].set_visible(False)
    
    plt.tight_layout()
    return fig

def plot_categorical_distributions(df, columns, cols=3):
    """–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤"""
    n = len(columns)
    rows = (n + cols - 1) // cols
    
    fig, axes = plt.subplots(rows, cols, figsize=(5*cols, 4*rows))
    if rows == 1:
        axes = [axes] if cols == 1 else axes
    else:
        axes = axes.flatten()
    
    for i, col in enumerate(columns):
        if i < len(axes):
            value_counts = df[col].value_counts().head(10)  # –¢–æ–ø-10 –∫–∞—Ç–µ–≥–æ—Ä–∏–π
            value_counts.plot(kind='bar', ax=axes[i], alpha=0.7)
            axes[i].set_title(f'–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ {col}')
            axes[i].set_xlabel(col)
            axes[i].set_ylabel('–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ')
            axes[i].tick_params(axis='x', rotation=45)
    
    # –°–∫—Ä—ã–≤–∞–µ–º –ø—É—Å—Ç—ã–µ subplots
    for i in range(n, len(axes)):
        axes[i].set_visible(False)
    
    plt.tight_layout()
    return fig

# –û—Å–Ω–æ–≤–Ω–æ–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ Streamlit
def main():
    st.set_page_config(page_title="Clustering Analysis App", layout="wide")
    st.title("üîç –ê–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω—ã—Ö –∏ –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è")
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è session_state –¥–ª—è –≥—Ä–∞—Ñ–∏–∫–æ–≤
    if 'df' not in st.session_state:
        st.session_state.df = None
    if 'processed_df' not in st.session_state:
        st.session_state.processed_df = None
    if 'clustered_df' not in st.session_state:
        st.session_state.clustered_df = None
    if 'clustering_done' not in st.session_state:
        st.session_state.clustering_done = False
    if 'tree_built' not in st.session_state:
        st.session_state.tree_built = False
    if 'optimal_clusters' not in st.session_state:
        st.session_state.optimal_clusters = None
    if 'X_processed' not in st.session_state:
        st.session_state.X_processed = None
    if 'num_cols' not in st.session_state:
        st.session_state.num_cols = None
    if 'cat_cols' not in st.session_state:
        st.session_state.cat_cols = None
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –¥–ª—è –≥—Ä–∞—Ñ–∏–∫–æ–≤ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏
    if 'preprocessing_figures' not in st.session_state:
        st.session_state.preprocessing_figures = {
            'numeric_distributions': None,
            'categorical_distributions': None
        }
    if 'preprocessing_completed' not in st.session_state:
        st.session_state.preprocessing_completed = False
    
    # –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
    st.header("1. –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö")
    uploaded_file = st.file_uploader("–ó–∞–≥—Ä—É–∑–∏—Ç–µ CSV –∏–ª–∏ Excel —Ñ–∞–π–ª", type=['csv', 'xlsx'])
    
    if uploaded_file is not None:
        try:
            if uploaded_file.name.endswith('.csv'):
                df = pd.read_csv(uploaded_file)
            else:
                df = pd.read_excel(uploaded_file)
            
            st.session_state.df = df
            st.success(f"‚úÖ –î–∞–Ω–Ω—ã–µ —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω—ã! –†–∞–∑–º–µ—Ä: {df.shape}")
            
            # –ü–æ–∫–∞–∑ –ø—Ä–µ–¥–ø—Ä–æ—Å–º–æ—Ç—Ä–∞ –¥–∞–Ω–Ω—ã—Ö
            st.subheader("–ü—Ä–µ–¥–ø—Ä–æ—Å–º–æ—Ç—Ä –¥–∞–Ω–Ω—ã—Ö")
            st.dataframe(df.head())

            # –í–´–ó–û–í –§–£–ù–ö–¶–ò–ò show_info
            show_info(df)
            
        except Exception as e:
            st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ —Ñ–∞–π–ª–∞: {e}")
    
    if st.session_state.df is not None:
        df = st.session_state.df
        
        # –í—ã–±–æ—Ä —Å—Ç–æ–ª–±—Ü–æ–≤
        st.header("2. –í—ã–±–æ—Ä —Å—Ç–æ–ª–±—Ü–æ–≤ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞")
        
        all_columns = df.columns.tolist()
        
        col1, col2 = st.columns(2)

        with col2:
            st.subheader("–¶–µ–ª–µ–≤–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è")
            target_options = [None] + all_columns
            selected_target = st.selectbox(
                "–í—ã–±–µ—Ä–∏—Ç–µ —Ü–µ–ª–µ–≤—É—é –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ):",
                options=target_options,
                index=0
            )

            if selected_target:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —Ç–∞—Ä–≥–µ—Ç —á–∏—Å–ª–æ–≤—ã–º
                target_dtype = df[selected_target].dtype
                is_numeric = pd.api.types.is_numeric_dtype(df[selected_target])
                
                if is_numeric:
                    st.success(f"‚úÖ –¶–µ–ª–µ–≤–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è: **{selected_target}**")
                    st.info(f"–¢–∏–ø –¥–∞–Ω–Ω—ã—Ö: {target_dtype}")
                    
                    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –±–∞–∑–æ–≤—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ —Ç–∞—Ä–≥–µ—Ç—É
                    target_stats = df[selected_target].describe()
                    st.write("**–ë–∞–∑–æ–≤–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:**")
                    st.write(f"- –ú–∏–Ω–∏–º—É–º: {target_stats['min']:.2f}")
                    st.write(f"- –ú–∞–∫—Å–∏–º—É–º: {target_stats['max']:.2f}")
                    st.write(f"- –°—Ä–µ–¥–Ω–µ–µ: {target_stats['mean']:.2f}")
                    st.write(f"- –ú–µ–¥–∏–∞–Ω–∞: {target_stats['50%']:.2f}")
                else:
                    st.error(f"‚ùå –¶–µ–ª–µ–≤–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è '{selected_target}' –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å —á–∏—Å–ª–æ–≤–æ–π!")
                    st.warning(f"–¢–µ–∫—É—â–∏–π —Ç–∏–ø: {target_dtype}")
                    st.info("üí° –î–ª—è –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è –≤ —á–∏—Å–ª–æ–≤–æ–π —Ñ–æ—Ä–º–∞—Ç –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫—É –¥–∞–Ω–Ω—ã—Ö")

        with col1:
            st.subheader("–í—Ö–æ–¥–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏")
            
            # –ò—Å–∫–ª—é—á–∞–µ–º —Ç–∞—Ä–≥–µ—Ç–Ω—É—é –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é –∏–∑ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –¥–ª—è –≤—ã–±–æ—Ä–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
            available_features = all_columns.copy()
            if selected_target and selected_target in available_features:
                available_features.remove(selected_target)
            
            # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –≤—ã–±–∏—Ä–∞–µ–º –ø—Ä–∏–∑–Ω–∞–∫–∏ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
            if len(available_features) > 0:
                default_features = available_features[:min(5, len(available_features))]
            else:
                default_features = []
            
            selected_features = st.multiselect(
                "–í—ã–±–µ—Ä–∏—Ç–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞:",
                options=available_features,
                default=default_features,
                help="–¢–∞—Ä–≥–µ—Ç–Ω–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∏—Å–∫–ª—é—á–µ–Ω–∞ –∏–∑ —Å–ø–∏—Å–∫–∞"
            )
            
            # –í–∞–ª–∏–¥–∞—Ü–∏—è
            if len(selected_features) == 0:
                st.error("‚ùå –ù–µ–æ–±—Ö–æ–¥–∏–º–æ –≤—ã–±—Ä–∞—Ç—å —Ö–æ—Ç—è –±—ã –æ–¥–∏–Ω –ø—Ä–∏–∑–Ω–∞–∫!")
            elif len(selected_features) == 1:
                st.warning("‚ö†Ô∏è –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –≤—ã–±—Ä–∞—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏")
            else:
                st.success(f"‚úÖ –í—ã–±—Ä–∞–Ω–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {len(selected_features)}")
        
        # –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö
        st.header("3. –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö")
        
        preprocessing_col1, preprocessing_col2 = st.columns(2)
        
        with preprocessing_col1:
            st.info("‚ÑπÔ∏è –ü—Ä–æ–ø—É—â–µ–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –≤—Å–µ–≥–¥–∞ —É–¥–∞–ª—è—é—Ç—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏")
            remove_outliers = st.checkbox("–£–¥–∞–ª–∏—Ç—å –≤—ã–±—Ä–æ—Å—ã", value=True)
        
        with preprocessing_col2:
            low_disp_threshold = st.slider(
                "–ü–æ—Ä–æ–≥ –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è –Ω–∏–∑–∫–æ–¥–∏—Å–ø–µ—Ä—Å–Ω—ã—Ö –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤:",
                min_value=0.8, max_value=1.0, value=0.95, step=0.01
            )
            outlier_multiplier = st.slider(
                "–ú–Ω–æ–∂–∏—Ç–µ–ª—å –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –≤—ã–±—Ä–æ—Å–æ–≤ (IQR):",
                min_value=1.0, max_value=3.0, value=1.5, step=0.1
            )
        
        if st.button("–ó–∞–ø—É—Å—Ç–∏—Ç—å –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫—É"):
            if len(selected_features) == 0:
                st.error("‚ùå –ù–µ–ª—å–∑—è –∑–∞–ø—É—Å—Ç–∏—Ç—å –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫—É –±–µ–∑ –≤—ã–±—Ä–∞–Ω–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤!")
            else:
                with st.spinner("–í—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö..."):
                    # –°–æ–∑–¥–∞–µ–º –∫–æ–ø–∏—é –¥–∞–Ω–Ω—ã—Ö —Å –≤—ã–±—Ä–∞–Ω–Ω—ã–º–∏ –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏
                    if selected_target and selected_target in selected_features:
                        features_to_use = [f for f in selected_features if f != selected_target]
                        st.warning(f"‚ö†Ô∏è –¢–∞—Ä–≥–µ—Ç–Ω–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è '{selected_target}' –∏—Å–∫–ª—é—á–µ–Ω–∞ –∏–∑ –≤—Ö–æ–¥–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")
                    else:
                        features_to_use = selected_features.copy()
                    
                    if selected_target:
                        processed_df = df[[selected_target] + features_to_use].copy()
                    else:
                        processed_df = df[features_to_use].copy()
                    
                    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —á–∏—Å–ª–æ–≤—ã–µ –∏ –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ —Å—Ç–æ–ª–±—Ü—ã
                    num_cols = processed_df.select_dtypes(include=[np.number]).columns.tolist()
                    cat_cols = processed_df.select_dtypes(include=['object', 'category']).columns.tolist()
                    
                    if selected_target and selected_target in num_cols:
                        num_cols.remove(selected_target)
                    if selected_target and selected_target in cat_cols:
                        cat_cols.remove(selected_target)
                    
                    # –ü—Ä–∏–º–µ–Ω—è–µ–º –æ—á–∏—Å—Ç–∫—É –¥–∞–Ω–Ω—ã—Ö (–≤—Å–µ–≥–¥–∞ —É–¥–∞–ª—è–µ–º –ø—Ä–æ–ø—É—Å–∫–∏)
                    numeric_for_cleaning = num_cols.copy()
                    if selected_target and processed_df[selected_target].dtype in [np.number]:
                        numeric_for_cleaning.append(selected_target)
                    
                    processed_df = comprehensive_clean_data_cached(
                        processed_df,
                        remove_outliers=remove_outliers,
                        outlier_multiplier=outlier_multiplier,
                        numeric_columns=numeric_for_cleaning
                    )
                    
                    # –£–¥–∞–ª—è–µ–º –Ω–∏–∑–∫–æ–¥–∏—Å–ø–µ—Ä—Å–Ω—ã–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
                    if cat_cols:
                        processed_df = delete_cat_with_zero_dispersion(
                            processed_df, cat_cols, threshold=low_disp_threshold
                        )
                        # –û–±–Ω–æ–≤–ª—è–µ–º —Å–ø–∏—Å–æ–∫ –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö —Å—Ç–æ–ª–±—Ü–æ–≤
                        cat_cols = processed_df.select_dtypes(include=['object', 'category']).columns.tolist()
                        if selected_target and selected_target in cat_cols:
                            cat_cols.remove(selected_target)
                    
                    st.session_state.processed_df = processed_df
                    st.session_state.num_cols = num_cols
                    st.session_state.cat_cols = cat_cols
                    st.session_state.selected_target = selected_target
                    st.session_state.clustering_done = False  # –°–±—Ä–∞—Å—ã–≤–∞–µ–º —Ñ–ª–∞–≥ –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏
                    st.session_state.tree_built = False  # –°–±—Ä–∞—Å—ã–≤–∞–µ–º —Ñ–ª–∞–≥ –¥–µ—Ä–µ–≤–∞
                    st.session_state.preprocessing_completed = True
                    
                    st.success(f"‚úÖ –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞! –ù–æ–≤—ã–π —Ä–∞–∑–º–µ—Ä: {processed_df.shape}")
                    
                    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ—Å–ª–µ –æ—á–∏—Å—Ç–∫–∏
                    st.subheader("–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ—Å–ª–µ –æ—á–∏—Å—Ç–∫–∏")
                    st.dataframe(processed_df.describe())
                    
                    # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–π –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ–º –≤ session_state
                    if num_cols:
                        st.subheader("–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —á–∏—Å–ª–æ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")
                        fig_num = plot_numeric_distributions(processed_df, num_cols)
                        st.session_state.preprocessing_figures['numeric_distributions'] = fig_num
                        st.pyplot(fig_num)
                    
                    if cat_cols:
                        st.subheader("–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")
                        fig_cat = plot_categorical_distributions(processed_df, cat_cols)
                        st.session_state.preprocessing_figures['categorical_distributions'] = fig_cat
                        st.pyplot(fig_cat)
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã–µ –≥—Ä–∞—Ñ–∏–∫–∏ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏, –µ—Å–ª–∏ –æ–Ω–∏ –µ—Å—Ç—å
        if st.session_state.preprocessing_completed:
            processed_df = st.session_state.processed_df
            num_cols = st.session_state.num_cols
            cat_cols = st.session_state.cat_cols
            
            # –í—Å–µ–≥–¥–∞ –ø–æ–∫–∞–∑—ã–≤–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
            st.subheader("–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ—Å–ª–µ –æ—á–∏—Å—Ç–∫–∏")
            st.dataframe(processed_df.describe())
            
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã–µ –≥—Ä–∞—Ñ–∏–∫–∏
            if st.session_state.preprocessing_figures['numeric_distributions'] and num_cols:
                st.subheader("–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —á–∏—Å–ª–æ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")
                st.pyplot(st.session_state.preprocessing_figures['numeric_distributions'])
            
            if st.session_state.preprocessing_figures['categorical_distributions'] and cat_cols:
                st.subheader("–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")
                st.pyplot(st.session_state.preprocessing_figures['categorical_distributions'])
        
        # –ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è
        if st.session_state.processed_df is not None:
            st.header("4. –ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è")
            
            processed_df = st.session_state.processed_df
            num_cols = st.session_state.num_cols
            cat_cols = st.session_state.cat_cols
            
            cluster_col1, cluster_col2 = st.columns(2)
            
            with cluster_col1:
                st.subheader("–ù–∞—Å—Ç—Ä–æ–π–∫–∏ –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏")
                use_auto_clusters = st.checkbox("–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –≤—ã–±–æ—Ä —á–∏—Å–ª–∞ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤ (elbow method)", value=True)
                
                if not use_auto_clusters:
                    n_clusters = st.slider("–ß–∏—Å–ª–æ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤:", min_value=2, max_value=20, value=4)
                else:
                    n_clusters = None
            
            with cluster_col2:
                st.subheader("–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –¥–∞–Ω–Ω—ã—Ö")
                st.write(f"–ß–∏—Å–ª–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏: {len(num_cols)}")
                st.write(f"–ö–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏: {len(cat_cols)}")
                st.write(f"–û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–±—Ä–∞–∑—Ü–æ–≤: {len(processed_df)}")
            
            if st.button("–ó–∞–ø—É—Å—Ç–∏—Ç—å –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—é"):
                with st.spinner("–í—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è..."):
                    try:
                        # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏
                        features_for_clustering = num_cols + cat_cols
                        X_processed, label_encoders, preprocessor = encoded_features_cached(
                            processed_df[features_for_clustering], num_cols, cat_cols
                        )
                        
                        # –î–µ–Ω–¥—Ä–æ–≥—Ä–∞–º–º–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
                        st.subheader("–î–µ–Ω–¥—Ä–æ–≥—Ä–∞–º–º–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")
                        dendro_fig = plot_dendogram_features(X_processed, features_for_clustering)
                        st.pyplot(dendro_fig)
                        
                        # –ò–µ—Ä–∞—Ä—Ö–∏—á–µ—Å–∫–∞—è –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è
                        Z = linkage(X_processed, method='ward', metric='euclidean')
                        
                        # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–≥–æ —á–∏—Å–ª–∞ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤
                        if use_auto_clusters:
                            inertias = []
                            cluster_range = range(2, min(20, len(processed_df)))
                            
                            for k in cluster_range:
                                inertia = calculate_inertia(Z, k, X_processed)
                                inertias.append(inertia)
                            
                            optimal_clusters = find_elbow_point(inertias, cluster_range)
                            st.info(f"üéØ –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –Ω–∞–π–¥–µ–Ω–æ –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–µ —á–∏—Å–ª–æ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤: {optimal_clusters}")
                        else:
                            optimal_clusters = n_clusters
                        
                        # –°–æ–∑–¥–∞–Ω–∏–µ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤
                        clusters = fcluster(Z, optimal_clusters, criterion='maxclust')
                        clustered_df = processed_df.copy()
                        clustered_df['Cluster'] = clusters
                        
                        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤—Å–µ –≤ session_state
                        st.session_state.clustered_df = clustered_df
                        st.session_state.optimal_clusters = optimal_clusters
                        st.session_state.X_processed = X_processed
                        st.session_state.clustering_done = True
                        st.session_state.tree_built = False  
                        
                        # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
                        st.subheader("–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏")
                        
                        # –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ –∫–ª–∞—Å—Ç–µ—Ä–∞–º
                        cluster_dist = clustered_df['Cluster'].value_counts().sort_index()
                        fig_cluster_dist, ax = plt.subplots(figsize=(10, 6))
                        bars = ax.bar(cluster_dist.index, cluster_dist.values, 
                                    color='lightcoral', edgecolor='darkred', alpha=0.7)
                        
                        for bar in bars:
                            height = bar.get_height()
                            percentage = (height / len(clustered_df)) * 100
                            ax.text(bar.get_x() + bar.get_width()/2., height,
                                   f'{int(height)}\n({percentage:.1f}%)', 
                                   ha='center', va='bottom', fontsize=9)
                        
                        ax.set_xlabel('–ö–ª–∞—Å—Ç–µ—Ä')
                        ax.set_ylabel('–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–±—Ä–∞–∑—Ü–æ–≤')
                        ax.set_title(f'–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ –∫–ª–∞—Å—Ç–µ—Ä–∞–º ({optimal_clusters} –∫–ª–∞—Å—Ç–µ—Ä–æ–≤)')
                        ax.grid(axis='y', alpha=0.3)
                        st.pyplot(fig_cluster_dist)
                        
                        # PCA –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è
                        pca = PCA(n_components=2)
                        X_pca = pca.fit_transform(X_processed)
                        
                        fig_pca, ax = plt.subplots(figsize=(12, 8))
                        scatter = ax.scatter(X_pca[:, 0], X_pca[:, 1], 
                                           c=clustered_df['Cluster'], 
                                           cmap='tab10', alpha=0.7, s=60,
                                           edgecolors='w', linewidth=0.5)
                        
                        plt.colorbar(scatter, ax=ax, label='–ö–ª–∞—Å—Ç–µ—Ä')
                        ax.set_title(f'–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –∫–ª–∞—Å—Ç–µ—Ä–æ–≤ —Å –ø–æ–º–æ—â—å—é PCA\n({optimal_clusters} –∫–ª–∞—Å—Ç–µ—Ä–æ–≤)')
                        ax.set_xlabel(f'–ì–ª–∞–≤–Ω–∞—è –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞ 1 ({pca.explained_variance_ratio_[0]:.2%})')
                        ax.set_ylabel(f'–ì–ª–∞–≤–Ω–∞—è –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞ 2 ({pca.explained_variance_ratio_[1]:.2%})')
                        ax.grid(alpha=0.3)
                        st.pyplot(fig_pca)
                        
                        # –ê–Ω–∞–ª–∏–∑ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤
                        st.subheader("–ê–Ω–∞–ª–∏–∑ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤")
                        
                        if num_cols:
                            st.write("**–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —á–∏—Å–ª–æ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –ø–æ –∫–ª–∞—Å—Ç–µ—Ä–∞–º:**")
                            numeric_summary = clustered_df.groupby('Cluster')[num_cols].mean()
                            st.dataframe(numeric_summary.style.background_gradient(cmap='Blues'))
                        
                        if cat_cols:
                            st.write("**–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –ø–æ –∫–ª–∞—Å—Ç–µ—Ä–∞–º:**")
                            for cat_col in cat_cols:
                                cross_tab = pd.crosstab(clustered_df['Cluster'], 
                                                       clustered_df[cat_col], 
                                                       normalize='index') * 100
                                st.write(f"**{cat_col}:**")
                                st.dataframe(cross_tab.style.background_gradient(cmap='Blues', axis=0))
                        
                    except Exception as e:
                        st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏: {e}")
            
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏, –µ—Å–ª–∏ –æ–Ω–∏ —É–∂–µ –µ—Å—Ç—å
            if st.session_state.clustering_done:
                clustered_df = st.session_state.clustered_df
                optimal_clusters = st.session_state.optimal_clusters
                num_cols = st.session_state.num_cols
                cat_cols = st.session_state.cat_cols
                
                # –î–µ—Ä–µ–≤–æ —Ä–µ—à–µ–Ω–∏–π –¥–ª—è –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏–∏ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤
                st.header("5. –ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è –∫–ª–∞—Å—Ç–µ—Ä–æ–≤ —Å –ø–æ–º–æ—â—å—é –¥–µ—Ä–µ–≤–∞ —Ä–µ—à–µ–Ω–∏–π")
                
                if st.button("–ü–æ—Å—Ç—Ä–æ–∏—Ç—å –¥–µ—Ä–µ–≤–æ —Ä–µ—à–µ–Ω–∏–π") or st.session_state.tree_built:
                    with st.spinner("–°—Ç—Ä–æ–∏–º –¥–µ—Ä–µ–≤–æ —Ä–µ—à–µ–Ω–∏–π..."):
                        try:
                            # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –¥–µ—Ä–µ–≤–∞
                            X_for_tree = clustered_df[num_cols + cat_cols].copy()
                            y_clusters = clustered_df['Cluster']
                            
                            # One-Hot –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–ª—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
                            X_encoded = pd.get_dummies(X_for_tree, columns=cat_cols, drop_first=True)
                            
                            # –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ train/test
                            X_train, X_test, y_train, y_test = train_test_split(
                                X_encoded, y_clusters, test_size=0.3, random_state=42, stratify=y_clusters
                            )
                            
                            # –û–±—É—á–∞–µ–º –¥–µ—Ä–µ–≤–æ —Ä–µ—à–µ–Ω–∏–π
                            tree_clf = DecisionTreeClassifier(
                                max_depth=4,
                                min_samples_split=20,
                                min_samples_leaf=10,
                                random_state=42
                            )
                            
                            tree_clf.fit(X_train, y_train)
                            
                            # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –¥–µ—Ä–µ–≤–∞
                            st.subheader("–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –¥–µ—Ä–µ–≤–∞ —Ä–µ—à–µ–Ω–∏–π")
                            fig_tree, ax = plt.subplots(figsize=(20, 12))
                            plot_tree(tree_clf,
                                     feature_names=X_encoded.columns.tolist(),
                                     class_names=[f'Cluster {i}' for i in range(1, optimal_clusters+1)],
                                     filled=True,
                                     rounded=True,
                                     fontsize=10,
                                     ax=ax)
                            ax.set_title('–î–µ—Ä–µ–≤–æ —Ä–µ—à–µ–Ω–∏–π –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –∫–ª–∞—Å—Ç–µ—Ä–æ–≤', 
                                       fontsize=16, fontweight='bold')
                            plt.tight_layout()
                            st.pyplot(fig_tree)
                            
                            # –í–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
                            st.subheader("–í–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")
                            feature_importance = pd.DataFrame({
                                'feature': X_encoded.columns,
                                'importance': tree_clf.feature_importances_
                            }).sort_values('importance', ascending=False)
                            
                            st.write("–¢–æ–ø-10 –Ω–∞–∏–±–æ–ª–µ–µ –≤–∞–∂–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤:")
                            # –°–±—Ä–∞—Å—ã–≤–∞–µ–º –∏–Ω–¥–µ–∫—Å –∏ –ø–µ—Ä–µ–∏–º–µ–Ω–æ–≤—ã–≤–∞–µ–º —Å—Ç–æ–ª–±–µ—Ü
                            feature_importance_reset = feature_importance.head(10).reset_index()
                            feature_importance_reset = feature_importance_reset.rename(columns={'index': '‚Ññ'})
                            feature_importance_reset = feature_importance_reset.drop(columns='‚Ññ')
                            st.dataframe(feature_importance_reset)
                            
                            # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –≤–∞–∂–Ω–æ—Å—Ç–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
                            fig_importance, ax = plt.subplots(figsize=(10, 6))
                            top_features = feature_importance.head(10)
                            top_features_sorted = top_features.sort_values('importance', ascending=True)
                            ax.barh(top_features_sorted['feature'], top_features_sorted['importance'])
                            ax.set_xlabel('–í–∞–∂–Ω–æ—Å—Ç—å')
                            ax.set_title('–¢–æ–ø-10 –Ω–∞–∏–±–æ–ª–µ–µ –≤–∞–∂–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –∫–ª–∞—Å—Ç–µ—Ä–æ–≤')
                            plt.tight_layout()
                            st.pyplot(fig_importance)
                            
                            st.session_state.tree_built = True
                            
                        except Exception as e:
                            st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏–∏ –¥–µ—Ä–µ–≤–∞: {e}")
            
            # –°–∫–∞—á–∏–≤–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            if st.session_state.clustering_done:
                st.header("6. –°–∫–∞—á–∏–≤–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")
                
                output = io.BytesIO()
                with pd.ExcelWriter(output, engine='openpyxl') as writer:
                    st.session_state.clustered_df.to_excel(writer, sheet_name='Clustered_Data', index=False)
                    
                    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –∫–ª–∞—Å—Ç–µ—Ä–∞–º
                    if st.session_state.num_cols or st.session_state.cat_cols:
                        cluster_stats = st.session_state.clustered_df.groupby('Cluster').agg({
                            **{col: 'mean' for col in st.session_state.num_cols},
                            **{col: lambda x: x.mode()[0] if len(x.mode()) > 0 else 'N/A' for col in st.session_state.cat_cols}
                        })
                        cluster_stats.to_excel(writer, sheet_name='Cluster_Statistics')
                
                output.seek(0)
                
                st.download_button(
                    label="üì• –°–∫–∞—á–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏ (Excel)",
                    data=output,
                    file_name=f"clustering_results_{st.session_state.optimal_clusters}_clusters.xlsx",
                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                )


if __name__ == "__main__":
    main()